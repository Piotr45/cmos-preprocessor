{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(\n",
    "    dataset: pd.DataFrame,\n",
    "    scaler: TransformerMixin,\n",
    "    validation_size: float = 0.2,\n",
    "    test_size: float = 0.1,\n",
    "    batch_size: int = 32,\n",
    "    random_state: int = 42,\n",
    ") -> Tuple[tf.data.Dataset]:\n",
    "    \"\"\"Converts a whole dataset into train, validation and test sets\n",
    "       as tf.data.Dataset pipelines\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): a dataframe containing X and y data\n",
    "        scaler (TransformerMixin): a transformer performing scaling\n",
    "        i.e StandardScaler()\n",
    "        validation_size (float, optional): the size of the validation\n",
    "        set (in percent). Defaults to 0.2.\n",
    "        test_size (float, optional): the size of the test set\n",
    "        (in percent). Defaults to 0.1.\n",
    "        batch_size (int, optional): the size of the batch during\n",
    "        training. Defaults to 32.\n",
    "    Returns:\n",
    "        Tuple[tf.data.Dataset]: a tuple containing train, validation\n",
    "        and test set pipelines\n",
    "    \"\"\"\n",
    "    X, y = dataset.iloc[:, :-1], dataset.iloc[:, -1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        train_size=1 - validation_size / (1 - test_size),\n",
    "        stratify=y_train,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # all features are actually the same feature from different\n",
    "    # timestamps\n",
    "\n",
    "    X_train_flattened = X_train.values.reshape(-1, 1)\n",
    "    scaler.fit(X_train_flattened)\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        X_train[[col]] = scaler.transform(X_train[[col]])\n",
    "        X_val[[col]] = scaler.transform(X_val[[col]])\n",
    "        X_test[[col]] = scaler.transform(X_test[[col]])\n",
    "\n",
    "    train_set = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(3)\n",
    "    )\n",
    "\n",
    "    val_set = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(3)\n",
    "    )\n",
    "\n",
    "    test_set = (\n",
    "        tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(3)\n",
    "    )\n",
    "\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d152ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1369cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def custom_sigmoid(x):\n",
    "    return 2 * K.sigmoid(37 * x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d5fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eb4006eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = {\n",
    "    7: 'dataset_freq_7.csv',\n",
    "    8: 'dataset_freq_8.csv',\n",
    "    9: 'dataset_freq_9.csv',\n",
    "    10: 'dataset_freq_10.csv',\n",
    "    11: 'dataset_freq_11.csv',\n",
    "    12: 'dataset_freq_12.csv',\n",
    "    13: 'dataset_freq_13.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d2dd9122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 4ms/step - loss: 0.6602 - accuracy: 0.6165 - val_loss: 0.6392 - val_accuracy: 0.6311\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6574 - val_loss: 0.5607 - val_accuracy: 0.7064\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7643 - val_loss: 0.4847 - val_accuracy: 0.8015\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8225 - val_loss: 0.4249 - val_accuracy: 0.8503\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8603 - val_loss: 0.3842 - val_accuracy: 0.8710\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8792 - val_loss: 0.3550 - val_accuracy: 0.8867\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8875 - val_loss: 0.3374 - val_accuracy: 0.8933\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8922 - val_loss: 0.3250 - val_accuracy: 0.8966\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8946 - val_loss: 0.3153 - val_accuracy: 0.8991\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2955 - accuracy: 0.8986 - val_loss: 0.3074 - val_accuracy: 0.9024\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9017 - val_loss: 0.3008 - val_accuracy: 0.9049\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.9035 - val_loss: 0.2954 - val_accuracy: 0.9107\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9040 - val_loss: 0.2907 - val_accuracy: 0.9082\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9057 - val_loss: 0.2866 - val_accuracy: 0.9082\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.9061 - val_loss: 0.2830 - val_accuracy: 0.9074\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9083 - val_loss: 0.2797 - val_accuracy: 0.9090\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9099 - val_loss: 0.2768 - val_accuracy: 0.9115\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9104 - val_loss: 0.2741 - val_accuracy: 0.9140\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9104 - val_loss: 0.2716 - val_accuracy: 0.9140\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.9104 - val_loss: 0.2694 - val_accuracy: 0.9140\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9097 - val_loss: 0.2674 - val_accuracy: 0.9140\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.9104 - val_loss: 0.2656 - val_accuracy: 0.9148\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9109 - val_loss: 0.2639 - val_accuracy: 0.9156\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9128 - val_loss: 0.2624 - val_accuracy: 0.9173\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9135 - val_loss: 0.2610 - val_accuracy: 0.9173\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.9142 - val_loss: 0.2598 - val_accuracy: 0.9173\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9139 - val_loss: 0.2586 - val_accuracy: 0.9181\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9135 - val_loss: 0.2576 - val_accuracy: 0.9181\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9132 - val_loss: 0.2566 - val_accuracy: 0.9181\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9135 - val_loss: 0.2557 - val_accuracy: 0.9181\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 3ms/step - loss: 0.6480 - accuracy: 0.6797 - val_loss: 0.5557 - val_accuracy: 0.7494\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7846 - val_loss: 0.4963 - val_accuracy: 0.7833\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8121 - val_loss: 0.4441 - val_accuracy: 0.7949\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8210 - val_loss: 0.4036 - val_accuracy: 0.8015\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8376 - val_loss: 0.3673 - val_accuracy: 0.8354\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8603 - val_loss: 0.3278 - val_accuracy: 0.8685\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8809 - val_loss: 0.2957 - val_accuracy: 0.8958\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8981 - val_loss: 0.2712 - val_accuracy: 0.9107\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9123 - val_loss: 0.2533 - val_accuracy: 0.9206\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.9203 - val_loss: 0.2389 - val_accuracy: 0.9239\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9241 - val_loss: 0.2274 - val_accuracy: 0.9256\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9265 - val_loss: 0.2185 - val_accuracy: 0.9272\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.9281 - val_loss: 0.2118 - val_accuracy: 0.9330\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9314 - val_loss: 0.2068 - val_accuracy: 0.9371\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9333 - val_loss: 0.2028 - val_accuracy: 0.9380\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9348 - val_loss: 0.1996 - val_accuracy: 0.9396\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9352 - val_loss: 0.1970 - val_accuracy: 0.9388\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9369 - val_loss: 0.1949 - val_accuracy: 0.9371\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9369 - val_loss: 0.1931 - val_accuracy: 0.9371\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9381 - val_loss: 0.1916 - val_accuracy: 0.9388\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9381 - val_loss: 0.1902 - val_accuracy: 0.9388\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9392 - val_loss: 0.1890 - val_accuracy: 0.9388\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9400 - val_loss: 0.1880 - val_accuracy: 0.9388\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9407 - val_loss: 0.1870 - val_accuracy: 0.9413\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9416 - val_loss: 0.1861 - val_accuracy: 0.9404\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.9416 - val_loss: 0.1853 - val_accuracy: 0.9404\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.1846 - val_accuracy: 0.9404\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9411 - val_loss: 0.1839 - val_accuracy: 0.9396\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9414 - val_loss: 0.1832 - val_accuracy: 0.9396\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9421 - val_loss: 0.1825 - val_accuracy: 0.9388\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 3ms/step - loss: 0.5765 - accuracy: 0.7454 - val_loss: 0.4862 - val_accuracy: 0.7792\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8038 - val_loss: 0.4174 - val_accuracy: 0.8304\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8454 - val_loss: 0.3579 - val_accuracy: 0.8677\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8887 - val_loss: 0.3094 - val_accuracy: 0.9065\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.9102 - val_loss: 0.2752 - val_accuracy: 0.9222\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.9225 - val_loss: 0.2505 - val_accuracy: 0.9330\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.9277 - val_loss: 0.2325 - val_accuracy: 0.9396\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9303 - val_loss: 0.2191 - val_accuracy: 0.9404\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9329 - val_loss: 0.2091 - val_accuracy: 0.9404\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9338 - val_loss: 0.2015 - val_accuracy: 0.9421\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9359 - val_loss: 0.1954 - val_accuracy: 0.9454\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9364 - val_loss: 0.1904 - val_accuracy: 0.9454\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9376 - val_loss: 0.1864 - val_accuracy: 0.9446\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9376 - val_loss: 0.1830 - val_accuracy: 0.9462\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9383 - val_loss: 0.1802 - val_accuracy: 0.9471\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9402 - val_loss: 0.1778 - val_accuracy: 0.9471\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9409 - val_loss: 0.1757 - val_accuracy: 0.9471\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9416 - val_loss: 0.1739 - val_accuracy: 0.9462\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9426 - val_loss: 0.1723 - val_accuracy: 0.9454\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9426 - val_loss: 0.1709 - val_accuracy: 0.9454\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9426 - val_loss: 0.1697 - val_accuracy: 0.9454\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9437 - val_loss: 0.1686 - val_accuracy: 0.9454\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9440 - val_loss: 0.1678 - val_accuracy: 0.9446\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9449 - val_loss: 0.1671 - val_accuracy: 0.9454\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9459 - val_loss: 0.1665 - val_accuracy: 0.9454\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9463 - val_loss: 0.1660 - val_accuracy: 0.9454\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9470 - val_loss: 0.1656 - val_accuracy: 0.9454\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9470 - val_loss: 0.1652 - val_accuracy: 0.9454\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9473 - val_loss: 0.1648 - val_accuracy: 0.9462\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9480 - val_loss: 0.1645 - val_accuracy: 0.9454\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.6730 - val_loss: 0.4774 - val_accuracy: 0.7783\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8102 - val_loss: 0.4027 - val_accuracy: 0.8313\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8513 - val_loss: 0.3500 - val_accuracy: 0.8693\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8870 - val_loss: 0.3109 - val_accuracy: 0.8974\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9113 - val_loss: 0.2825 - val_accuracy: 0.9181\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.9227 - val_loss: 0.2592 - val_accuracy: 0.9222\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9284 - val_loss: 0.2381 - val_accuracy: 0.9338\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9345 - val_loss: 0.2239 - val_accuracy: 0.9347\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9388 - val_loss: 0.2138 - val_accuracy: 0.9355\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1994 - accuracy: 0.9416 - val_loss: 0.2060 - val_accuracy: 0.9371\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9437 - val_loss: 0.1999 - val_accuracy: 0.9380\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9452 - val_loss: 0.1949 - val_accuracy: 0.9388\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9456 - val_loss: 0.1908 - val_accuracy: 0.9413\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9463 - val_loss: 0.1874 - val_accuracy: 0.9438\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9470 - val_loss: 0.1845 - val_accuracy: 0.9438\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1659 - accuracy: 0.9482 - val_loss: 0.1821 - val_accuracy: 0.9446\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9496 - val_loss: 0.1801 - val_accuracy: 0.9446\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9504 - val_loss: 0.1782 - val_accuracy: 0.9438\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9511 - val_loss: 0.1766 - val_accuracy: 0.9438\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9515 - val_loss: 0.1751 - val_accuracy: 0.9446\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9520 - val_loss: 0.1737 - val_accuracy: 0.9454\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9530 - val_loss: 0.1725 - val_accuracy: 0.9454\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9537 - val_loss: 0.1714 - val_accuracy: 0.9454\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9544 - val_loss: 0.1704 - val_accuracy: 0.9446\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9541 - val_loss: 0.1695 - val_accuracy: 0.9454\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.1688 - val_accuracy: 0.9471\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9553 - val_loss: 0.1681 - val_accuracy: 0.9471\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9560 - val_loss: 0.1675 - val_accuracy: 0.9479\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9558 - val_loss: 0.1669 - val_accuracy: 0.9471\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9565 - val_loss: 0.1663 - val_accuracy: 0.9471\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 3ms/step - loss: 0.6103 - accuracy: 0.6846 - val_loss: 0.4941 - val_accuracy: 0.7601\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7983 - val_loss: 0.4163 - val_accuracy: 0.8371\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8610 - val_loss: 0.3636 - val_accuracy: 0.8685\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8882 - val_loss: 0.3138 - val_accuracy: 0.8925\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.9106 - val_loss: 0.2769 - val_accuracy: 0.9140\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.9191 - val_loss: 0.2532 - val_accuracy: 0.9214\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9265 - val_loss: 0.2364 - val_accuracy: 0.9289\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2297 - accuracy: 0.9314 - val_loss: 0.2242 - val_accuracy: 0.9313\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9345 - val_loss: 0.2148 - val_accuracy: 0.9330\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9369 - val_loss: 0.2073 - val_accuracy: 0.9363\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9381 - val_loss: 0.2011 - val_accuracy: 0.9371\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9388 - val_loss: 0.1957 - val_accuracy: 0.9388\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9404 - val_loss: 0.1910 - val_accuracy: 0.9396\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9416 - val_loss: 0.1868 - val_accuracy: 0.9396\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1743 - accuracy: 0.9428 - val_loss: 0.1829 - val_accuracy: 0.9396\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9461 - val_loss: 0.1793 - val_accuracy: 0.9404\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9466 - val_loss: 0.1766 - val_accuracy: 0.9413\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9482 - val_loss: 0.1746 - val_accuracy: 0.9421\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9492 - val_loss: 0.1727 - val_accuracy: 0.9438\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 0.1711 - val_accuracy: 0.9454\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9492 - val_loss: 0.1695 - val_accuracy: 0.9454\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9494 - val_loss: 0.1681 - val_accuracy: 0.9438\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9496 - val_loss: 0.1668 - val_accuracy: 0.9438\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9501 - val_loss: 0.1656 - val_accuracy: 0.9446\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9511 - val_loss: 0.1644 - val_accuracy: 0.9446\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9511 - val_loss: 0.1633 - val_accuracy: 0.9446\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9515 - val_loss: 0.1622 - val_accuracy: 0.9454\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9522 - val_loss: 0.1611 - val_accuracy: 0.9454\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9522 - val_loss: 0.1600 - val_accuracy: 0.9446\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9530 - val_loss: 0.1590 - val_accuracy: 0.9446\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 3ms/step - loss: 0.6286 - accuracy: 0.6697 - val_loss: 0.5000 - val_accuracy: 0.7907\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8106 - val_loss: 0.4146 - val_accuracy: 0.8412\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8409 - val_loss: 0.3681 - val_accuracy: 0.8569\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8655 - val_loss: 0.3260 - val_accuracy: 0.8908\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8998 - val_loss: 0.2887 - val_accuracy: 0.9123\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2905 - accuracy: 0.9154 - val_loss: 0.2633 - val_accuracy: 0.9156\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9229 - val_loss: 0.2443 - val_accuracy: 0.9222\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.9286 - val_loss: 0.2295 - val_accuracy: 0.9289\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9326 - val_loss: 0.2177 - val_accuracy: 0.9289\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9338 - val_loss: 0.2082 - val_accuracy: 0.9305\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9355 - val_loss: 0.2010 - val_accuracy: 0.9297\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9381 - val_loss: 0.1955 - val_accuracy: 0.9313\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9397 - val_loss: 0.1912 - val_accuracy: 0.9330\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9397 - val_loss: 0.1879 - val_accuracy: 0.9363\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9407 - val_loss: 0.1854 - val_accuracy: 0.9355\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9421 - val_loss: 0.1836 - val_accuracy: 0.9380\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9433 - val_loss: 0.1828 - val_accuracy: 0.9380\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9430 - val_loss: 0.1813 - val_accuracy: 0.9380\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9428 - val_loss: 0.1785 - val_accuracy: 0.9371\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9442 - val_loss: 0.1763 - val_accuracy: 0.9388\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9449 - val_loss: 0.1744 - val_accuracy: 0.9388\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9452 - val_loss: 0.1727 - val_accuracy: 0.9413\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9456 - val_loss: 0.1711 - val_accuracy: 0.9421\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9459 - val_loss: 0.1697 - val_accuracy: 0.9438\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9475 - val_loss: 0.1684 - val_accuracy: 0.9438\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9482 - val_loss: 0.1673 - val_accuracy: 0.9438\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9482 - val_loss: 0.1663 - val_accuracy: 0.9454\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9489 - val_loss: 0.1653 - val_accuracy: 0.9454\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9492 - val_loss: 0.1645 - val_accuracy: 0.9462\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9496 - val_loss: 0.1637 - val_accuracy: 0.9471\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 4ms/step - loss: 0.6433 - accuracy: 0.6806 - val_loss: 0.5612 - val_accuracy: 0.7477\n",
      "Epoch 2/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7641 - val_loss: 0.4553 - val_accuracy: 0.7907\n",
      "Epoch 3/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.8087 - val_loss: 0.3884 - val_accuracy: 0.8296\n",
      "Epoch 4/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8456 - val_loss: 0.3386 - val_accuracy: 0.8734\n",
      "Epoch 5/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8861 - val_loss: 0.2962 - val_accuracy: 0.9074\n",
      "Epoch 6/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.9064 - val_loss: 0.2653 - val_accuracy: 0.9198\n",
      "Epoch 7/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9173 - val_loss: 0.2438 - val_accuracy: 0.9239\n",
      "Epoch 8/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9234 - val_loss: 0.2280 - val_accuracy: 0.9264\n",
      "Epoch 9/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9281 - val_loss: 0.2157 - val_accuracy: 0.9338\n",
      "Epoch 10/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9314 - val_loss: 0.2059 - val_accuracy: 0.9355\n",
      "Epoch 11/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9338 - val_loss: 0.1980 - val_accuracy: 0.9371\n",
      "Epoch 12/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9355 - val_loss: 0.1918 - val_accuracy: 0.9413\n",
      "Epoch 13/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9374 - val_loss: 0.1868 - val_accuracy: 0.9429\n",
      "Epoch 14/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9392 - val_loss: 0.1825 - val_accuracy: 0.9462\n",
      "Epoch 15/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9407 - val_loss: 0.1787 - val_accuracy: 0.9495\n",
      "Epoch 16/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9430 - val_loss: 0.1754 - val_accuracy: 0.9495\n",
      "Epoch 17/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9442 - val_loss: 0.1727 - val_accuracy: 0.9520\n",
      "Epoch 18/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9454 - val_loss: 0.1703 - val_accuracy: 0.9529\n",
      "Epoch 19/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9461 - val_loss: 0.1682 - val_accuracy: 0.9553\n",
      "Epoch 20/30\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9466 - val_loss: 0.1662 - val_accuracy: 0.9545\n",
      "Epoch 21/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9473 - val_loss: 0.1644 - val_accuracy: 0.9545\n",
      "Epoch 22/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9487 - val_loss: 0.1626 - val_accuracy: 0.9562\n",
      "Epoch 23/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9489 - val_loss: 0.1609 - val_accuracy: 0.9570\n",
      "Epoch 24/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9501 - val_loss: 0.1593 - val_accuracy: 0.9562\n",
      "Epoch 25/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9501 - val_loss: 0.1576 - val_accuracy: 0.9562\n",
      "Epoch 26/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1471 - accuracy: 0.9506 - val_loss: 0.1561 - val_accuracy: 0.9562\n",
      "Epoch 27/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9520 - val_loss: 0.1546 - val_accuracy: 0.9545\n",
      "Epoch 28/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9530 - val_loss: 0.1531 - val_accuracy: 0.9553\n",
      "Epoch 29/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9530 - val_loss: 0.1518 - val_accuracy: 0.9562\n",
      "Epoch 30/30\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9532 - val_loss: 0.1505 - val_accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for freq, csv_name in dataset_dir.items():\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=0.005,\n",
    "    momentum=0.9,\n",
    "    nesterov=True)\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    train_set, val_set, test_set = get_datasets(pd.read_csv(csv_name), scaler)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(freq,)),\n",
    "        tf.keras.layers.Dense(freq, use_bias=False),\n",
    "        tf.keras.layers.Activation(custom_sigmoid, name='custom_sigmoid'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', use_bias=False)\n",
    "    ])\n",
    "    model.compile(optimizer=opt,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(train_set, epochs=30,\n",
    "                    validation_data=val_set)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "585cd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_acc = [history.history['val_accuracy'][-1] for history in histories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "20b8ddc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9181141257286072,\n",
       " 0.9387924075126648,\n",
       " 0.9454094171524048,\n",
       " 0.947063684463501,\n",
       " 0.9445822834968567,\n",
       " 0.947063684463501,\n",
       " 0.9561620950698853]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6298516e",
   "metadata": {},
   "source": [
    "Najwiksz warto ma input 13 (czego mona si byo domyli), ale decydujemy si na 10, bo jest tasza sprztowo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "09fc7f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781e19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\kicpe\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set, test_set = get_datasets(pd.read_csv('dataset_freq_10.csv'), scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b025f",
   "metadata": {},
   "source": [
    "# ==== DLA NATALII ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fb811a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 11)\n"
     ]
    }
   ],
   "source": [
    "dt = np.dtype(np.int32)  \n",
    "arr = np.array([1,2,3])\n",
    "arr_ = np.array([2,3,4])\n",
    "\n",
    "ls = []\n",
    "# arr = np.append(arr, [[1,2]], axis=1)\n",
    "# arr = np.append(arr, [[2,3]], axis=0)\n",
    "# arr = np.append(arr, [[2,3]], axis=0)\n",
    "# print(arr)\n",
    "for s in test_set:\n",
    "    for idx, row in enumerate(s[0]):\n",
    "        single_row = np.concatenate((np.array(row), np.array(s[1][idx])), axis=None)\n",
    "        ls.append(single_row)\n",
    "        \n",
    "ls = np.array(ls)\n",
    "print(ls.shape)\n",
    "\n",
    "pd.DataFrame(ls).to_csv(\"dla_natalii.csv\", header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a35be4",
   "metadata": {},
   "source": [
    "# ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32a27574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-483f2516ea0469e5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-483f2516ea0469e5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6005;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --port 6005 --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fef5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_regularizers = [\n",
    "    tf.keras.regularizers.L2(l2=0.008),\n",
    "    tf.keras.regularizers.L2(l2=0.007),\n",
    "    tf.keras.regularizers.L2(l2=0.006)\n",
    "]\n",
    "\n",
    "init_kernels = [\n",
    "    'glorot_normal',\n",
    "    'he_normal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46b704fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l2_regularizer, init_kernel):\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ]\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(10,)),\n",
    "        tf.keras.layers.Dense(10, use_bias=False, kernel_initializer=init_kernel, \n",
    "                            kernel_regularizer=l2_regularizer),\n",
    "        tf.keras.layers.Activation(custom_sigmoid, name='custom_sigmoid'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid', use_bias=False, kernel_initializer=init_kernel,\n",
    "                                  kernel_regularizer=l2_regularizer)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=metrics)\n",
    "    return model\n",
    "\n",
    "def train_model(model, l2_regularizer, init_kernel):\n",
    "    log_dir = \"logs/fit/\" + str(l2_regularizer.l2) + '_' + init_kernel\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                          histogram_freq=1,\n",
    "                                                          write_images=True)\n",
    "    early_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=1e-3)\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_set, \n",
    "        epochs=250, \n",
    "        validation_data=val_set, \n",
    "        callbacks=[tensorboard_callback, early_callback, reduce_lr]) \n",
    "    \n",
    "    return model, history\n",
    "    \n",
    "def evaluate_model(model):\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ]\n",
    "    model.layers[-1].activate = custom_sigmoid\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), \n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics)\n",
    "    res = model.evaluate(test_set)\n",
    "    return res, model\n",
    "\n",
    "def process_models(l2_regularizers, init_kernels):\n",
    "    results, models, histories = [], [], []\n",
    "    for init_kernel in init_kernels:\n",
    "        for l2_regularizer in l2_regularizers:\n",
    "            model = build_model(l2_regularizer, init_kernel)\n",
    "            model, history = train_model(model, l2_regularizer, init_kernel)\n",
    "            res, model = evaluate_model(model)\n",
    "            results.append(res)\n",
    "            models.append(model)\n",
    "            histories.append(history)\n",
    "    return results, models, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb0e975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "133/133 [==============================] - 2s 10ms/step - loss: 0.6372 - auc: 0.7789 - recall: 0.4700 - precision: 0.7739 - accuracy: 0.7449 - val_loss: 0.5276 - val_auc: 0.8857 - val_recall: 0.6212 - val_precision: 0.8645 - val_accuracy: 0.8180 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4967 - auc: 0.9114 - recall: 0.6759 - precision: 0.8879 - accuracy: 0.8435 - val_loss: 0.4688 - val_auc: 0.9342 - val_recall: 0.7532 - val_precision: 0.8810 - val_accuracy: 0.8668 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4478 - auc: 0.9463 - recall: 0.7755 - precision: 0.9214 - accuracy: 0.8889 - val_loss: 0.4357 - val_auc: 0.9551 - val_recall: 0.8723 - val_precision: 0.8818 - val_accuracy: 0.9065 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4224 - auc: 0.9586 - recall: 0.8312 - precision: 0.9250 - accuracy: 0.9097 - val_loss: 0.4156 - val_auc: 0.9644 - val_recall: 0.8896 - val_precision: 0.8820 - val_accuracy: 0.9123 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4077 - auc: 0.9643 - recall: 0.8516 - precision: 0.9367 - accuracy: 0.9213 - val_loss: 0.4067 - val_auc: 0.9681 - val_recall: 0.8939 - val_precision: 0.9017 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4016 - auc: 0.9674 - recall: 0.8602 - precision: 0.9469 - accuracy: 0.9281 - val_loss: 0.4027 - val_auc: 0.9704 - val_recall: 0.9004 - val_precision: 0.9083 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3985 - auc: 0.9693 - recall: 0.8639 - precision: 0.9497 - accuracy: 0.9305 - val_loss: 0.3997 - val_auc: 0.9721 - val_recall: 0.9048 - val_precision: 0.9167 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3962 - auc: 0.9707 - recall: 0.8658 - precision: 0.9517 - accuracy: 0.9319 - val_loss: 0.3974 - val_auc: 0.9732 - val_recall: 0.9026 - val_precision: 0.9165 - val_accuracy: 0.9313 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3946 - auc: 0.9718 - recall: 0.8652 - precision: 0.9523 - accuracy: 0.9319 - val_loss: 0.3960 - val_auc: 0.9739 - val_recall: 0.9026 - val_precision: 0.9145 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3936 - auc: 0.9724 - recall: 0.8670 - precision: 0.9518 - accuracy: 0.9324 - val_loss: 0.3951 - val_auc: 0.9744 - val_recall: 0.9026 - val_precision: 0.9205 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3929 - auc: 0.9729 - recall: 0.8689 - precision: 0.9525 - accuracy: 0.9333 - val_loss: 0.3947 - val_auc: 0.9746 - val_recall: 0.9004 - val_precision: 0.9224 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3924 - auc: 0.9731 - recall: 0.8689 - precision: 0.9538 - accuracy: 0.9338 - val_loss: 0.3944 - val_auc: 0.9749 - val_recall: 0.9004 - val_precision: 0.9224 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3921 - auc: 0.9734 - recall: 0.8683 - precision: 0.9545 - accuracy: 0.9338 - val_loss: 0.3941 - val_auc: 0.9751 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3919 - auc: 0.9735 - recall: 0.8683 - precision: 0.9538 - accuracy: 0.9336 - val_loss: 0.3939 - val_auc: 0.9752 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3918 - auc: 0.9736 - recall: 0.8683 - precision: 0.9545 - accuracy: 0.9338 - val_loss: 0.3938 - val_auc: 0.9753 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3917 - auc: 0.9737 - recall: 0.8689 - precision: 0.9551 - accuracy: 0.9343 - val_loss: 0.3937 - val_auc: 0.9753 - val_recall: 0.9004 - val_precision: 0.9244 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3916 - auc: 0.9738 - recall: 0.8695 - precision: 0.9552 - accuracy: 0.9345 - val_loss: 0.3936 - val_auc: 0.9754 - val_recall: 0.9004 - val_precision: 0.9244 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3915 - auc: 0.9739 - recall: 0.8689 - precision: 0.9551 - accuracy: 0.9343 - val_loss: 0.3935 - val_auc: 0.9755 - val_recall: 0.9004 - val_precision: 0.9244 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3914 - auc: 0.9739 - recall: 0.8695 - precision: 0.9545 - accuracy: 0.9343 - val_loss: 0.3935 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3914 - auc: 0.9739 - recall: 0.8707 - precision: 0.9546 - accuracy: 0.9348 - val_loss: 0.3934 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3914 - auc: 0.9740 - recall: 0.8701 - precision: 0.9545 - accuracy: 0.9345 - val_loss: 0.3934 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3913 - auc: 0.9740 - recall: 0.8695 - precision: 0.9545 - accuracy: 0.9343 - val_loss: 0.3934 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3913 - auc: 0.9740 - recall: 0.8701 - precision: 0.9545 - accuracy: 0.9345 - val_loss: 0.3934 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3913 - auc: 0.9740 - recall: 0.8701 - precision: 0.9545 - accuracy: 0.9345 - val_loss: 0.3933 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3913 - auc: 0.9740 - recall: 0.8683 - precision: 0.9545 - accuracy: 0.9338 - val_loss: 0.3933 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3912 - auc: 0.9740 - recall: 0.8677 - precision: 0.9551 - accuracy: 0.9338 - val_loss: 0.3933 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3912 - auc: 0.9740 - recall: 0.8677 - precision: 0.9551 - accuracy: 0.9338 - val_loss: 0.3933 - val_auc: 0.9755 - val_recall: 0.8983 - val_precision: 0.9243 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "19/19 [==============================] - 1s 5ms/step - loss: 0.3768 - auc: 0.9845 - recall: 0.9177 - precision: 0.9298 - accuracy: 0.9421\n",
      "Epoch 1/250\n",
      "133/133 [==============================] - 3s 12ms/step - loss: 0.6001 - auc: 0.8147 - recall: 0.5226 - precision: 0.8212 - accuracy: 0.7740 - val_loss: 0.4983 - val_auc: 0.9049 - val_recall: 0.7251 - val_precision: 0.8333 - val_accuracy: 0.8395 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4636 - auc: 0.9316 - recall: 0.7291 - precision: 0.9154 - accuracy: 0.8707 - val_loss: 0.4485 - val_auc: 0.9443 - val_recall: 0.8550 - val_precision: 0.8681 - val_accuracy: 0.8950 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4275 - auc: 0.9521 - recall: 0.8052 - precision: 0.9367 - accuracy: 0.9047 - val_loss: 0.4288 - val_auc: 0.9543 - val_recall: 0.8810 - val_precision: 0.8829 - val_accuracy: 0.9098 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4113 - auc: 0.9589 - recall: 0.8275 - precision: 0.9416 - accuracy: 0.9144 - val_loss: 0.4184 - val_auc: 0.9584 - val_recall: 0.8810 - val_precision: 0.8965 - val_accuracy: 0.9156 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4033 - auc: 0.9619 - recall: 0.8466 - precision: 0.9435 - accuracy: 0.9220 - val_loss: 0.4131 - val_auc: 0.9606 - val_recall: 0.8896 - val_precision: 0.9033 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3995 - auc: 0.9635 - recall: 0.8479 - precision: 0.9442 - accuracy: 0.9227 - val_loss: 0.4104 - val_auc: 0.9615 - val_recall: 0.8874 - val_precision: 0.9051 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3977 - auc: 0.9644 - recall: 0.8491 - precision: 0.9469 - accuracy: 0.9241 - val_loss: 0.4087 - val_auc: 0.9623 - val_recall: 0.8853 - val_precision: 0.9049 - val_accuracy: 0.9206 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3964 - auc: 0.9651 - recall: 0.8522 - precision: 0.9432 - accuracy: 0.9239 - val_loss: 0.4071 - val_auc: 0.9629 - val_recall: 0.8810 - val_precision: 0.9044 - val_accuracy: 0.9189 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3951 - auc: 0.9656 - recall: 0.8534 - precision: 0.9433 - accuracy: 0.9243 - val_loss: 0.4054 - val_auc: 0.9636 - val_recall: 0.8853 - val_precision: 0.9069 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3936 - auc: 0.9662 - recall: 0.8528 - precision: 0.9432 - accuracy: 0.9241 - val_loss: 0.4024 - val_auc: 0.9646 - val_recall: 0.8810 - val_precision: 0.9065 - val_accuracy: 0.9198 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3891 - auc: 0.9674 - recall: 0.8609 - precision: 0.9431 - accuracy: 0.9270 - val_loss: 0.3932 - val_auc: 0.9670 - val_recall: 0.8788 - val_precision: 0.9124 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3838 - auc: 0.9690 - recall: 0.8639 - precision: 0.9458 - accuracy: 0.9291 - val_loss: 0.3906 - val_auc: 0.9679 - val_recall: 0.8723 - val_precision: 0.9118 - val_accuracy: 0.9189 - lr: 0.0100\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3820 - auc: 0.9697 - recall: 0.8639 - precision: 0.9465 - accuracy: 0.9293 - val_loss: 0.3895 - val_auc: 0.9684 - val_recall: 0.8745 - val_precision: 0.9099 - val_accuracy: 0.9189 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3812 - auc: 0.9701 - recall: 0.8658 - precision: 0.9472 - accuracy: 0.9303 - val_loss: 0.3889 - val_auc: 0.9689 - val_recall: 0.8766 - val_precision: 0.9101 - val_accuracy: 0.9198 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3807 - auc: 0.9703 - recall: 0.8646 - precision: 0.9459 - accuracy: 0.9293 - val_loss: 0.3884 - val_auc: 0.9692 - val_recall: 0.8788 - val_precision: 0.9103 - val_accuracy: 0.9206 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3804 - auc: 0.9705 - recall: 0.8639 - precision: 0.9458 - accuracy: 0.9291 - val_loss: 0.3880 - val_auc: 0.9694 - val_recall: 0.8810 - val_precision: 0.9105 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3801 - auc: 0.9706 - recall: 0.8639 - precision: 0.9458 - accuracy: 0.9291 - val_loss: 0.3878 - val_auc: 0.9697 - val_recall: 0.8810 - val_precision: 0.9105 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3799 - auc: 0.9707 - recall: 0.8658 - precision: 0.9466 - accuracy: 0.9300 - val_loss: 0.3875 - val_auc: 0.9698 - val_recall: 0.8831 - val_precision: 0.9107 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3797 - auc: 0.9709 - recall: 0.8670 - precision: 0.9467 - accuracy: 0.9305 - val_loss: 0.3873 - val_auc: 0.9699 - val_recall: 0.8831 - val_precision: 0.9107 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3796 - auc: 0.9710 - recall: 0.8677 - precision: 0.9473 - accuracy: 0.9310 - val_loss: 0.3870 - val_auc: 0.9701 - val_recall: 0.8831 - val_precision: 0.9107 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3794 - auc: 0.9710 - recall: 0.8689 - precision: 0.9474 - accuracy: 0.9314 - val_loss: 0.3868 - val_auc: 0.9702 - val_recall: 0.8853 - val_precision: 0.9129 - val_accuracy: 0.9239 - lr: 0.0100\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3792 - auc: 0.9711 - recall: 0.8689 - precision: 0.9480 - accuracy: 0.9317 - val_loss: 0.3866 - val_auc: 0.9703 - val_recall: 0.8874 - val_precision: 0.9131 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3790 - auc: 0.9712 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3864 - val_auc: 0.9705 - val_recall: 0.8874 - val_precision: 0.9131 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3789 - auc: 0.9713 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3862 - val_auc: 0.9706 - val_recall: 0.8896 - val_precision: 0.9133 - val_accuracy: 0.9256 - lr: 0.0100\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3787 - auc: 0.9713 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3860 - val_auc: 0.9707 - val_recall: 0.8918 - val_precision: 0.9135 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3786 - auc: 0.9713 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3859 - val_auc: 0.9709 - val_recall: 0.8918 - val_precision: 0.9135 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3785 - auc: 0.9713 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3857 - val_auc: 0.9710 - val_recall: 0.8918 - val_precision: 0.9135 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3784 - auc: 0.9714 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3855 - val_auc: 0.9712 - val_recall: 0.8918 - val_precision: 0.9135 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3782 - auc: 0.9714 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3853 - val_auc: 0.9713 - val_recall: 0.8918 - val_precision: 0.9135 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3779 - auc: 0.9715 - recall: 0.8683 - precision: 0.9480 - accuracy: 0.9314 - val_loss: 0.3849 - val_auc: 0.9715 - val_recall: 0.8939 - val_precision: 0.9117 - val_accuracy: 0.9264 - lr: 0.0100\n",
      "Epoch 31/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3775 - auc: 0.9716 - recall: 0.8689 - precision: 0.9480 - accuracy: 0.9317 - val_loss: 0.3844 - val_auc: 0.9717 - val_recall: 0.8961 - val_precision: 0.9119 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 32/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3771 - auc: 0.9716 - recall: 0.8695 - precision: 0.9487 - accuracy: 0.9322 - val_loss: 0.3838 - val_auc: 0.9719 - val_recall: 0.8961 - val_precision: 0.9119 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 33/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3767 - auc: 0.9717 - recall: 0.8707 - precision: 0.9488 - accuracy: 0.9326 - val_loss: 0.3833 - val_auc: 0.9720 - val_recall: 0.8961 - val_precision: 0.9119 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3765 - auc: 0.9717 - recall: 0.8695 - precision: 0.9474 - accuracy: 0.9317 - val_loss: 0.3831 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9119 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 35/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3764 - auc: 0.9717 - recall: 0.8689 - precision: 0.9468 - accuracy: 0.9312 - val_loss: 0.3829 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9119 - val_accuracy: 0.9272 - lr: 0.0100\n",
      "Epoch 36/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3764 - auc: 0.9717 - recall: 0.8695 - precision: 0.9468 - accuracy: 0.9314 - val_loss: 0.3827 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 37/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9717 - recall: 0.8695 - precision: 0.9468 - accuracy: 0.9314 - val_loss: 0.3826 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 38/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9717 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3825 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 39/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3824 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 40/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9717 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3824 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 41/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3823 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 42/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3823 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 43/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8695 - precision: 0.9462 - accuracy: 0.9312 - val_loss: 0.3823 - val_auc: 0.9721 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 44/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8689 - precision: 0.9461 - accuracy: 0.9310 - val_loss: 0.3823 - val_auc: 0.9722 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 45/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8689 - precision: 0.9461 - accuracy: 0.9310 - val_loss: 0.3823 - val_auc: 0.9723 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "Epoch 46/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9718 - recall: 0.8683 - precision: 0.9455 - accuracy: 0.9305 - val_loss: 0.3823 - val_auc: 0.9723 - val_recall: 0.8961 - val_precision: 0.9139 - val_accuracy: 0.9280 - lr: 0.0100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3643 - auc: 0.9791 - recall: 0.9134 - precision: 0.9378 - accuracy: 0.9438\n",
      "Epoch 1/250\n",
      "133/133 [==============================] - 2s 9ms/step - loss: 0.6528 - auc: 0.7483 - recall: 0.4409 - precision: 0.6746 - accuracy: 0.7050 - val_loss: 0.5512 - val_auc: 0.8502 - val_recall: 0.6494 - val_precision: 0.7712 - val_accuracy: 0.7924 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5084 - auc: 0.8928 - recall: 0.7087 - precision: 0.8782 - accuracy: 0.8511 - val_loss: 0.4681 - val_auc: 0.9283 - val_recall: 0.7446 - val_precision: 0.8821 - val_accuracy: 0.8644 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4441 - auc: 0.9410 - recall: 0.7557 - precision: 0.9286 - accuracy: 0.8844 - val_loss: 0.4251 - val_auc: 0.9614 - val_recall: 0.8398 - val_precision: 0.9044 - val_accuracy: 0.9049 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4059 - auc: 0.9632 - recall: 0.8157 - precision: 0.9448 - accuracy: 0.9113 - val_loss: 0.3997 - val_auc: 0.9700 - val_recall: 0.9134 - val_precision: 0.9095 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3848 - auc: 0.9714 - recall: 0.8578 - precision: 0.9546 - accuracy: 0.9300 - val_loss: 0.3878 - val_auc: 0.9721 - val_recall: 0.9177 - val_precision: 0.9158 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3749 - auc: 0.9741 - recall: 0.8707 - precision: 0.9565 - accuracy: 0.9355 - val_loss: 0.3823 - val_auc: 0.9728 - val_recall: 0.9242 - val_precision: 0.9242 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3691 - auc: 0.9755 - recall: 0.8776 - precision: 0.9562 - accuracy: 0.9378 - val_loss: 0.3797 - val_auc: 0.9730 - val_recall: 0.9221 - val_precision: 0.9281 - val_accuracy: 0.9429 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3655 - auc: 0.9764 - recall: 0.8813 - precision: 0.9564 - accuracy: 0.9392 - val_loss: 0.3783 - val_auc: 0.9731 - val_recall: 0.9221 - val_precision: 0.9261 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3627 - auc: 0.9773 - recall: 0.8837 - precision: 0.9571 - accuracy: 0.9404 - val_loss: 0.3763 - val_auc: 0.9734 - val_recall: 0.9242 - val_precision: 0.9262 - val_accuracy: 0.9429 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3598 - auc: 0.9778 - recall: 0.8862 - precision: 0.9566 - accuracy: 0.9411 - val_loss: 0.3729 - val_auc: 0.9742 - val_recall: 0.9221 - val_precision: 0.9261 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3576 - auc: 0.9781 - recall: 0.8850 - precision: 0.9585 - accuracy: 0.9414 - val_loss: 0.3712 - val_auc: 0.9745 - val_recall: 0.9199 - val_precision: 0.9259 - val_accuracy: 0.9413 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3565 - auc: 0.9783 - recall: 0.8862 - precision: 0.9579 - accuracy: 0.9416 - val_loss: 0.3705 - val_auc: 0.9748 - val_recall: 0.9199 - val_precision: 0.9279 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3559 - auc: 0.9785 - recall: 0.8837 - precision: 0.9578 - accuracy: 0.9407 - val_loss: 0.3702 - val_auc: 0.9750 - val_recall: 0.9199 - val_precision: 0.9279 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3555 - auc: 0.9787 - recall: 0.8844 - precision: 0.9572 - accuracy: 0.9407 - val_loss: 0.3700 - val_auc: 0.9750 - val_recall: 0.9156 - val_precision: 0.9276 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3552 - auc: 0.9787 - recall: 0.8844 - precision: 0.9578 - accuracy: 0.9409 - val_loss: 0.3700 - val_auc: 0.9750 - val_recall: 0.9134 - val_precision: 0.9275 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3550 - auc: 0.9787 - recall: 0.8837 - precision: 0.9578 - accuracy: 0.9407 - val_loss: 0.3699 - val_auc: 0.9749 - val_recall: 0.9134 - val_precision: 0.9275 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3549 - auc: 0.9788 - recall: 0.8837 - precision: 0.9571 - accuracy: 0.9404 - val_loss: 0.3700 - val_auc: 0.9750 - val_recall: 0.9134 - val_precision: 0.9295 - val_accuracy: 0.9404 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3547 - auc: 0.9788 - recall: 0.8850 - precision: 0.9585 - accuracy: 0.9414 - val_loss: 0.3700 - val_auc: 0.9749 - val_recall: 0.9134 - val_precision: 0.9295 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3546 - auc: 0.9788 - recall: 0.8850 - precision: 0.9585 - accuracy: 0.9414 - val_loss: 0.3701 - val_auc: 0.9748 - val_recall: 0.9134 - val_precision: 0.9295 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3517 - auc: 0.9805 - recall: 0.8831 - precision: 0.9629 - accuracy: 0.9423 - val_loss: 0.3627 - val_auc: 0.9755 - val_recall: 0.8831 - val_precision: 0.9423 - val_accuracy: 0.9347 - lr: 0.0020\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3503 - auc: 0.9806 - recall: 0.8868 - precision: 0.9624 - accuracy: 0.9435 - val_loss: 0.3627 - val_auc: 0.9754 - val_recall: 0.8853 - val_precision: 0.9402 - val_accuracy: 0.9347 - lr: 0.0020\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3502 - auc: 0.9805 - recall: 0.8868 - precision: 0.9605 - accuracy: 0.9428 - val_loss: 0.3627 - val_auc: 0.9753 - val_recall: 0.8853 - val_precision: 0.9402 - val_accuracy: 0.9347 - lr: 0.0020\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3501 - auc: 0.9805 - recall: 0.8868 - precision: 0.9611 - accuracy: 0.9430 - val_loss: 0.3627 - val_auc: 0.9753 - val_recall: 0.8853 - val_precision: 0.9402 - val_accuracy: 0.9347 - lr: 0.0020\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3501 - auc: 0.9805 - recall: 0.8862 - precision: 0.9611 - accuracy: 0.9428 - val_loss: 0.3627 - val_auc: 0.9753 - val_recall: 0.8853 - val_precision: 0.9402 - val_accuracy: 0.9347 - lr: 0.0020\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3500 - auc: 0.9805 - recall: 0.8862 - precision: 0.9611 - accuracy: 0.9428 - val_loss: 0.3627 - val_auc: 0.9753 - val_recall: 0.8874 - val_precision: 0.9404 - val_accuracy: 0.9355 - lr: 0.0020\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3493 - auc: 0.9810 - recall: 0.8893 - precision: 0.9599 - accuracy: 0.9435 - val_loss: 0.3627 - val_auc: 0.9754 - val_recall: 0.8874 - val_precision: 0.9404 - val_accuracy: 0.9355 - lr: 4.0000e-04\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3490 - auc: 0.9810 - recall: 0.8874 - precision: 0.9624 - accuracy: 0.9437 - val_loss: 0.3626 - val_auc: 0.9753 - val_recall: 0.8874 - val_precision: 0.9361 - val_accuracy: 0.9338 - lr: 4.0000e-04\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3490 - auc: 0.9810 - recall: 0.8887 - precision: 0.9625 - accuracy: 0.9442 - val_loss: 0.3626 - val_auc: 0.9754 - val_recall: 0.8874 - val_precision: 0.9361 - val_accuracy: 0.9338 - lr: 4.0000e-04\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3489 - auc: 0.9810 - recall: 0.8887 - precision: 0.9625 - accuracy: 0.9442 - val_loss: 0.3626 - val_auc: 0.9754 - val_recall: 0.8874 - val_precision: 0.9361 - val_accuracy: 0.9338 - lr: 4.0000e-04\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3489 - auc: 0.9809 - recall: 0.8893 - precision: 0.9625 - accuracy: 0.9444 - val_loss: 0.3626 - val_auc: 0.9753 - val_recall: 0.8874 - val_precision: 0.9361 - val_accuracy: 0.9338 - lr: 4.0000e-04\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3382 - auc: 0.9835 - recall: 0.9221 - precision: 0.9682 - accuracy: 0.9587\n",
      "Epoch 1/250\n",
      "133/133 [==============================] - 2s 9ms/step - loss: 0.7267 - auc: 0.7248 - recall: 0.3408 - precision: 0.7497 - accuracy: 0.7045 - val_loss: 0.6315 - val_auc: 0.8202 - val_recall: 0.5087 - val_precision: 0.8333 - val_accuracy: 0.7734 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5845 - auc: 0.8577 - recall: 0.6017 - precision: 0.8782 - accuracy: 0.8158 - val_loss: 0.5557 - val_auc: 0.8742 - val_recall: 0.6212 - val_precision: 0.8441 - val_accuracy: 0.8114 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5279 - auc: 0.9006 - recall: 0.6481 - precision: 0.9250 - accuracy: 0.8454 - val_loss: 0.5131 - val_auc: 0.9145 - val_recall: 0.7165 - val_precision: 0.8597 - val_accuracy: 0.8470 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4868 - auc: 0.9319 - recall: 0.6895 - precision: 0.9417 - accuracy: 0.8650 - val_loss: 0.4752 - val_auc: 0.9454 - val_recall: 0.7749 - val_precision: 0.8883 - val_accuracy: 0.8768 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4488 - auc: 0.9545 - recall: 0.7532 - precision: 0.9538 - accuracy: 0.8917 - val_loss: 0.4507 - val_auc: 0.9605 - val_recall: 0.8636 - val_precision: 0.9048 - val_accuracy: 0.9132 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.4333 - auc: 0.9616 - recall: 0.7916 - precision: 0.9581 - accuracy: 0.9071 - val_loss: 0.4435 - val_auc: 0.9642 - val_recall: 0.8896 - val_precision: 0.9033 - val_accuracy: 0.9214 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4264 - auc: 0.9651 - recall: 0.8151 - precision: 0.9585 - accuracy: 0.9158 - val_loss: 0.4383 - val_auc: 0.9662 - val_recall: 0.8961 - val_precision: 0.9079 - val_accuracy: 0.9256 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.4214 - auc: 0.9673 - recall: 0.8244 - precision: 0.9576 - accuracy: 0.9189 - val_loss: 0.4327 - val_auc: 0.9679 - val_recall: 0.9113 - val_precision: 0.9113 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4173 - auc: 0.9688 - recall: 0.8312 - precision: 0.9566 - accuracy: 0.9210 - val_loss: 0.4273 - val_auc: 0.9691 - val_recall: 0.9091 - val_precision: 0.9190 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4138 - auc: 0.9701 - recall: 0.8398 - precision: 0.9563 - accuracy: 0.9241 - val_loss: 0.4219 - val_auc: 0.9700 - val_recall: 0.9091 - val_precision: 0.9231 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4086 - auc: 0.9717 - recall: 0.8534 - precision: 0.9597 - accuracy: 0.9303 - val_loss: 0.4138 - val_auc: 0.9711 - val_recall: 0.9004 - val_precision: 0.9244 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4037 - auc: 0.9731 - recall: 0.8578 - precision: 0.9619 - accuracy: 0.9326 - val_loss: 0.4103 - val_auc: 0.9717 - val_recall: 0.9026 - val_precision: 0.9371 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4014 - auc: 0.9739 - recall: 0.8609 - precision: 0.9620 - accuracy: 0.9338 - val_loss: 0.4080 - val_auc: 0.9722 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3997 - auc: 0.9744 - recall: 0.8646 - precision: 0.9615 - accuracy: 0.9350 - val_loss: 0.4067 - val_auc: 0.9726 - val_recall: 0.8983 - val_precision: 0.9347 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3986 - auc: 0.9748 - recall: 0.8652 - precision: 0.9609 - accuracy: 0.9350 - val_loss: 0.4058 - val_auc: 0.9728 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3977 - auc: 0.9750 - recall: 0.8670 - precision: 0.9616 - accuracy: 0.9359 - val_loss: 0.4051 - val_auc: 0.9731 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3970 - auc: 0.9752 - recall: 0.8677 - precision: 0.9623 - accuracy: 0.9364 - val_loss: 0.4046 - val_auc: 0.9732 - val_recall: 0.9004 - val_precision: 0.9369 - val_accuracy: 0.9388 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3964 - auc: 0.9753 - recall: 0.8683 - precision: 0.9623 - accuracy: 0.9366 - val_loss: 0.4041 - val_auc: 0.9735 - val_recall: 0.9004 - val_precision: 0.9369 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3959 - auc: 0.9754 - recall: 0.8695 - precision: 0.9624 - accuracy: 0.9371 - val_loss: 0.4036 - val_auc: 0.9737 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3955 - auc: 0.9755 - recall: 0.8701 - precision: 0.9624 - accuracy: 0.9374 - val_loss: 0.4032 - val_auc: 0.9737 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3951 - auc: 0.9755 - recall: 0.8701 - precision: 0.9630 - accuracy: 0.9376 - val_loss: 0.4028 - val_auc: 0.9739 - val_recall: 0.8983 - val_precision: 0.9368 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3948 - auc: 0.9756 - recall: 0.8707 - precision: 0.9631 - accuracy: 0.9378 - val_loss: 0.4024 - val_auc: 0.9741 - val_recall: 0.9004 - val_precision: 0.9369 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3945 - auc: 0.9756 - recall: 0.8720 - precision: 0.9631 - accuracy: 0.9383 - val_loss: 0.4021 - val_auc: 0.9743 - val_recall: 0.9004 - val_precision: 0.9369 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3943 - auc: 0.9757 - recall: 0.8726 - precision: 0.9631 - accuracy: 0.9385 - val_loss: 0.4019 - val_auc: 0.9744 - val_recall: 0.9026 - val_precision: 0.9371 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3942 - auc: 0.9758 - recall: 0.8738 - precision: 0.9632 - accuracy: 0.9390 - val_loss: 0.4017 - val_auc: 0.9745 - val_recall: 0.9026 - val_precision: 0.9371 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3940 - auc: 0.9758 - recall: 0.8738 - precision: 0.9632 - accuracy: 0.9390 - val_loss: 0.4015 - val_auc: 0.9746 - val_recall: 0.9026 - val_precision: 0.9371 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3939 - auc: 0.9758 - recall: 0.8745 - precision: 0.9632 - accuracy: 0.9392 - val_loss: 0.4013 - val_auc: 0.9747 - val_recall: 0.9048 - val_precision: 0.9372 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3938 - auc: 0.9759 - recall: 0.8738 - precision: 0.9625 - accuracy: 0.9388 - val_loss: 0.4012 - val_auc: 0.9747 - val_recall: 0.9069 - val_precision: 0.9374 - val_accuracy: 0.9413 - lr: 0.0100\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3938 - auc: 0.9759 - recall: 0.8745 - precision: 0.9626 - accuracy: 0.9390 - val_loss: 0.4011 - val_auc: 0.9748 - val_recall: 0.9069 - val_precision: 0.9374 - val_accuracy: 0.9413 - lr: 0.0100\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3937 - auc: 0.9759 - recall: 0.8745 - precision: 0.9626 - accuracy: 0.9390 - val_loss: 0.4010 - val_auc: 0.9750 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 31/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3937 - auc: 0.9758 - recall: 0.8757 - precision: 0.9626 - accuracy: 0.9395 - val_loss: 0.4009 - val_auc: 0.9750 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 32/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3936 - auc: 0.9758 - recall: 0.8757 - precision: 0.9626 - accuracy: 0.9395 - val_loss: 0.4008 - val_auc: 0.9750 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 33/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3936 - auc: 0.9759 - recall: 0.8757 - precision: 0.9626 - accuracy: 0.9395 - val_loss: 0.4008 - val_auc: 0.9750 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 34/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3936 - auc: 0.9759 - recall: 0.8757 - precision: 0.9626 - accuracy: 0.9395 - val_loss: 0.4007 - val_auc: 0.9751 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "Epoch 35/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3936 - auc: 0.9758 - recall: 0.8757 - precision: 0.9626 - accuracy: 0.9395 - val_loss: 0.4007 - val_auc: 0.9752 - val_recall: 0.9069 - val_precision: 0.9395 - val_accuracy: 0.9421 - lr: 0.0100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3805 - auc: 0.9847 - recall: 0.9221 - precision: 0.9301 - accuracy: 0.9438\n",
      "Epoch 1/250\n",
      "133/133 [==============================] - 2s 8ms/step - loss: 0.6724 - auc: 0.7805 - recall: 0.5541 - precision: 0.7344 - accuracy: 0.7530 - val_loss: 0.5777 - val_auc: 0.8596 - val_recall: 0.6667 - val_precision: 0.8280 - val_accuracy: 0.8197 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.5393 - auc: 0.8866 - recall: 0.6815 - precision: 0.8781 - accuracy: 0.8421 - val_loss: 0.5048 - val_auc: 0.9080 - val_recall: 0.7121 - val_precision: 0.8545 - val_accuracy: 0.8437 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4824 - auc: 0.9220 - recall: 0.7180 - precision: 0.8979 - accuracy: 0.8610 - val_loss: 0.4691 - val_auc: 0.9309 - val_recall: 0.7727 - val_precision: 0.8707 - val_accuracy: 0.8693 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4537 - auc: 0.9388 - recall: 0.7638 - precision: 0.9101 - accuracy: 0.8809 - val_loss: 0.4467 - val_auc: 0.9437 - val_recall: 0.8312 - val_precision: 0.8727 - val_accuracy: 0.8892 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.4326 - auc: 0.9490 - recall: 0.8021 - precision: 0.9192 - accuracy: 0.8974 - val_loss: 0.4281 - val_auc: 0.9526 - val_recall: 0.8420 - val_precision: 0.8801 - val_accuracy: 0.8958 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4159 - auc: 0.9563 - recall: 0.8237 - precision: 0.9250 - accuracy: 0.9071 - val_loss: 0.4151 - val_auc: 0.9588 - val_recall: 0.8831 - val_precision: 0.8870 - val_accuracy: 0.9123 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4052 - auc: 0.9608 - recall: 0.8380 - precision: 0.9332 - accuracy: 0.9151 - val_loss: 0.4077 - val_auc: 0.9624 - val_recall: 0.8853 - val_precision: 0.8930 - val_accuracy: 0.9156 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3994 - auc: 0.9636 - recall: 0.8491 - precision: 0.9372 - accuracy: 0.9206 - val_loss: 0.4036 - val_auc: 0.9648 - val_recall: 0.8853 - val_precision: 0.8950 - val_accuracy: 0.9165 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3956 - auc: 0.9655 - recall: 0.8510 - precision: 0.9405 - accuracy: 0.9225 - val_loss: 0.4004 - val_auc: 0.9667 - val_recall: 0.8896 - val_precision: 0.9053 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3923 - auc: 0.9672 - recall: 0.8547 - precision: 0.9421 - accuracy: 0.9243 - val_loss: 0.3976 - val_auc: 0.9681 - val_recall: 0.8983 - val_precision: 0.9041 - val_accuracy: 0.9247 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3898 - auc: 0.9685 - recall: 0.8571 - precision: 0.9454 - accuracy: 0.9265 - val_loss: 0.3954 - val_auc: 0.9693 - val_recall: 0.9026 - val_precision: 0.9105 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3879 - auc: 0.9695 - recall: 0.8565 - precision: 0.9493 - accuracy: 0.9277 - val_loss: 0.3933 - val_auc: 0.9702 - val_recall: 0.9004 - val_precision: 0.9123 - val_accuracy: 0.9289 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3862 - auc: 0.9705 - recall: 0.8596 - precision: 0.9508 - accuracy: 0.9293 - val_loss: 0.3913 - val_auc: 0.9709 - val_recall: 0.8983 - val_precision: 0.9181 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3844 - auc: 0.9714 - recall: 0.8602 - precision: 0.9534 - accuracy: 0.9305 - val_loss: 0.3889 - val_auc: 0.9716 - val_recall: 0.8983 - val_precision: 0.9222 - val_accuracy: 0.9322 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3825 - auc: 0.9723 - recall: 0.8615 - precision: 0.9541 - accuracy: 0.9312 - val_loss: 0.3865 - val_auc: 0.9724 - val_recall: 0.9004 - val_precision: 0.9224 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3807 - auc: 0.9731 - recall: 0.8646 - precision: 0.9556 - accuracy: 0.9329 - val_loss: 0.3846 - val_auc: 0.9732 - val_recall: 0.9004 - val_precision: 0.9224 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3793 - auc: 0.9738 - recall: 0.8658 - precision: 0.9569 - accuracy: 0.9338 - val_loss: 0.3830 - val_auc: 0.9741 - val_recall: 0.9004 - val_precision: 0.9244 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3781 - auc: 0.9744 - recall: 0.8689 - precision: 0.9577 - accuracy: 0.9352 - val_loss: 0.3816 - val_auc: 0.9748 - val_recall: 0.9026 - val_precision: 0.9246 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3772 - auc: 0.9749 - recall: 0.8714 - precision: 0.9579 - accuracy: 0.9362 - val_loss: 0.3805 - val_auc: 0.9753 - val_recall: 0.9026 - val_precision: 0.9267 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3763 - auc: 0.9753 - recall: 0.8726 - precision: 0.9592 - accuracy: 0.9371 - val_loss: 0.3797 - val_auc: 0.9756 - val_recall: 0.9026 - val_precision: 0.9308 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3757 - auc: 0.9756 - recall: 0.8751 - precision: 0.9593 - accuracy: 0.9381 - val_loss: 0.3791 - val_auc: 0.9757 - val_recall: 0.9026 - val_precision: 0.9267 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3753 - auc: 0.9759 - recall: 0.8763 - precision: 0.9594 - accuracy: 0.9385 - val_loss: 0.3786 - val_auc: 0.9759 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3750 - auc: 0.9760 - recall: 0.8757 - precision: 0.9600 - accuracy: 0.9385 - val_loss: 0.3783 - val_auc: 0.9761 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3748 - auc: 0.9761 - recall: 0.8763 - precision: 0.9600 - accuracy: 0.9388 - val_loss: 0.3782 - val_auc: 0.9762 - val_recall: 0.9004 - val_precision: 0.9265 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3745 - auc: 0.9763 - recall: 0.8769 - precision: 0.9601 - accuracy: 0.9390 - val_loss: 0.3780 - val_auc: 0.9763 - val_recall: 0.9026 - val_precision: 0.9287 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3743 - auc: 0.9764 - recall: 0.8776 - precision: 0.9601 - accuracy: 0.9392 - val_loss: 0.3777 - val_auc: 0.9763 - val_recall: 0.9026 - val_precision: 0.9287 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3741 - auc: 0.9764 - recall: 0.8763 - precision: 0.9600 - accuracy: 0.9388 - val_loss: 0.3774 - val_auc: 0.9763 - val_recall: 0.9026 - val_precision: 0.9287 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3740 - auc: 0.9765 - recall: 0.8763 - precision: 0.9600 - accuracy: 0.9388 - val_loss: 0.3772 - val_auc: 0.9763 - val_recall: 0.8983 - val_precision: 0.9284 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3739 - auc: 0.9765 - recall: 0.8763 - precision: 0.9600 - accuracy: 0.9388 - val_loss: 0.3770 - val_auc: 0.9763 - val_recall: 0.8983 - val_precision: 0.9305 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3738 - auc: 0.9766 - recall: 0.8757 - precision: 0.9600 - accuracy: 0.9385 - val_loss: 0.3768 - val_auc: 0.9764 - val_recall: 0.9004 - val_precision: 0.9306 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 31/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3737 - auc: 0.9766 - recall: 0.8751 - precision: 0.9600 - accuracy: 0.9383 - val_loss: 0.3766 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9329 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 32/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3736 - auc: 0.9767 - recall: 0.8757 - precision: 0.9600 - accuracy: 0.9385 - val_loss: 0.3764 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9329 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 33/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3734 - auc: 0.9768 - recall: 0.8757 - precision: 0.9600 - accuracy: 0.9385 - val_loss: 0.3762 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9329 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 34/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3733 - auc: 0.9768 - recall: 0.8763 - precision: 0.9594 - accuracy: 0.9385 - val_loss: 0.3760 - val_auc: 0.9763 - val_recall: 0.9048 - val_precision: 0.9330 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 35/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3731 - auc: 0.9769 - recall: 0.8763 - precision: 0.9587 - accuracy: 0.9383 - val_loss: 0.3758 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9350 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 36/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3730 - auc: 0.9769 - recall: 0.8757 - precision: 0.9587 - accuracy: 0.9381 - val_loss: 0.3756 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9371 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 37/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3728 - auc: 0.9770 - recall: 0.8763 - precision: 0.9587 - accuracy: 0.9383 - val_loss: 0.3755 - val_auc: 0.9764 - val_recall: 0.9026 - val_precision: 0.9392 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 38/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3727 - auc: 0.9770 - recall: 0.8745 - precision: 0.9586 - accuracy: 0.9376 - val_loss: 0.3754 - val_auc: 0.9765 - val_recall: 0.9026 - val_precision: 0.9392 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 39/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3727 - auc: 0.9770 - recall: 0.8745 - precision: 0.9586 - accuracy: 0.9376 - val_loss: 0.3753 - val_auc: 0.9763 - val_recall: 0.9026 - val_precision: 0.9392 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 40/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3726 - auc: 0.9771 - recall: 0.8738 - precision: 0.9580 - accuracy: 0.9371 - val_loss: 0.3753 - val_auc: 0.9762 - val_recall: 0.9026 - val_precision: 0.9350 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 41/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3725 - auc: 0.9771 - recall: 0.8738 - precision: 0.9580 - accuracy: 0.9371 - val_loss: 0.3753 - val_auc: 0.9763 - val_recall: 0.9048 - val_precision: 0.9351 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 42/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3724 - auc: 0.9771 - recall: 0.8738 - precision: 0.9580 - accuracy: 0.9371 - val_loss: 0.3753 - val_auc: 0.9762 - val_recall: 0.9048 - val_precision: 0.9351 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 43/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3724 - auc: 0.9771 - recall: 0.8732 - precision: 0.9579 - accuracy: 0.9369 - val_loss: 0.3753 - val_auc: 0.9762 - val_recall: 0.9048 - val_precision: 0.9351 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 44/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3692 - auc: 0.9787 - recall: 0.8782 - precision: 0.9608 - accuracy: 0.9397 - val_loss: 0.3704 - val_auc: 0.9772 - val_recall: 0.8961 - val_precision: 0.9474 - val_accuracy: 0.9413 - lr: 0.0020\n",
      "Epoch 45/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3680 - auc: 0.9788 - recall: 0.8806 - precision: 0.9615 - accuracy: 0.9409 - val_loss: 0.3703 - val_auc: 0.9771 - val_recall: 0.8961 - val_precision: 0.9452 - val_accuracy: 0.9404 - lr: 0.0020\n",
      "Epoch 46/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3679 - auc: 0.9787 - recall: 0.8806 - precision: 0.9622 - accuracy: 0.9411 - val_loss: 0.3703 - val_auc: 0.9770 - val_recall: 0.8961 - val_precision: 0.9452 - val_accuracy: 0.9404 - lr: 0.0020\n",
      "Epoch 47/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3679 - auc: 0.9788 - recall: 0.8806 - precision: 0.9622 - accuracy: 0.9411 - val_loss: 0.3703 - val_auc: 0.9770 - val_recall: 0.8961 - val_precision: 0.9452 - val_accuracy: 0.9404 - lr: 0.0020\n",
      "Epoch 48/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3679 - auc: 0.9788 - recall: 0.8806 - precision: 0.9622 - accuracy: 0.9411 - val_loss: 0.3703 - val_auc: 0.9770 - val_recall: 0.8961 - val_precision: 0.9452 - val_accuracy: 0.9404 - lr: 0.0020\n",
      "Epoch 49/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3678 - auc: 0.9788 - recall: 0.8806 - precision: 0.9622 - accuracy: 0.9411 - val_loss: 0.3703 - val_auc: 0.9770 - val_recall: 0.8939 - val_precision: 0.9451 - val_accuracy: 0.9396 - lr: 0.0020\n",
      "Epoch 50/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3678 - auc: 0.9788 - recall: 0.8806 - precision: 0.9622 - accuracy: 0.9411 - val_loss: 0.3703 - val_auc: 0.9769 - val_recall: 0.8939 - val_precision: 0.9451 - val_accuracy: 0.9396 - lr: 0.0020\n",
      "Epoch 51/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3671 - auc: 0.9792 - recall: 0.8825 - precision: 0.9609 - accuracy: 0.9414 - val_loss: 0.3705 - val_auc: 0.9772 - val_recall: 0.9026 - val_precision: 0.9456 - val_accuracy: 0.9429 - lr: 4.0000e-04\n",
      "Epoch 52/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3668 - auc: 0.9792 - recall: 0.8819 - precision: 0.9609 - accuracy: 0.9411 - val_loss: 0.3704 - val_auc: 0.9772 - val_recall: 0.9048 - val_precision: 0.9457 - val_accuracy: 0.9438 - lr: 4.0000e-04\n",
      "Epoch 53/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3667 - auc: 0.9792 - recall: 0.8813 - precision: 0.9609 - accuracy: 0.9409 - val_loss: 0.3703 - val_auc: 0.9773 - val_recall: 0.9048 - val_precision: 0.9457 - val_accuracy: 0.9438 - lr: 4.0000e-04\n",
      "Epoch 54/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3667 - auc: 0.9792 - recall: 0.8806 - precision: 0.9609 - accuracy: 0.9407 - val_loss: 0.3703 - val_auc: 0.9774 - val_recall: 0.9048 - val_precision: 0.9457 - val_accuracy: 0.9438 - lr: 4.0000e-04\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3509 - auc: 0.9867 - recall: 0.9177 - precision: 0.9507 - accuracy: 0.9504\n",
      "Epoch 1/250\n",
      "133/133 [==============================] - 2s 10ms/step - loss: 0.6733 - auc: 0.7832 - recall: 0.4335 - precision: 0.7402 - accuracy: 0.7253 - val_loss: 0.5513 - val_auc: 0.8914 - val_recall: 0.6385 - val_precision: 0.8728 - val_accuracy: 0.8263 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.5169 - auc: 0.9054 - recall: 0.6648 - precision: 0.8966 - accuracy: 0.8426 - val_loss: 0.4823 - val_auc: 0.9262 - val_recall: 0.7446 - val_precision: 0.8557 - val_accuracy: 0.8544 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4648 - auc: 0.9330 - recall: 0.7322 - precision: 0.8963 - accuracy: 0.8652 - val_loss: 0.4448 - val_auc: 0.9462 - val_recall: 0.8420 - val_precision: 0.8664 - val_accuracy: 0.8900 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4302 - auc: 0.9497 - recall: 0.7978 - precision: 0.9123 - accuracy: 0.8934 - val_loss: 0.4217 - val_auc: 0.9557 - val_recall: 0.8723 - val_precision: 0.8723 - val_accuracy: 0.9024 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.4086 - auc: 0.9576 - recall: 0.8194 - precision: 0.9195 - accuracy: 0.9035 - val_loss: 0.4049 - val_auc: 0.9609 - val_recall: 0.8918 - val_precision: 0.8822 - val_accuracy: 0.9132 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3946 - auc: 0.9623 - recall: 0.8380 - precision: 0.9287 - accuracy: 0.9135 - val_loss: 0.3958 - val_auc: 0.9638 - val_recall: 0.9026 - val_precision: 0.8948 - val_accuracy: 0.9222 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3867 - auc: 0.9654 - recall: 0.8472 - precision: 0.9339 - accuracy: 0.9187 - val_loss: 0.3904 - val_auc: 0.9660 - val_recall: 0.9113 - val_precision: 0.8957 - val_accuracy: 0.9256 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3810 - auc: 0.9679 - recall: 0.8541 - precision: 0.9388 - accuracy: 0.9229 - val_loss: 0.3856 - val_auc: 0.9679 - val_recall: 0.9091 - val_precision: 0.8974 - val_accuracy: 0.9256 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3759 - auc: 0.9698 - recall: 0.8609 - precision: 0.9431 - accuracy: 0.9270 - val_loss: 0.3808 - val_auc: 0.9703 - val_recall: 0.9113 - val_precision: 0.9034 - val_accuracy: 0.9289 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3709 - auc: 0.9716 - recall: 0.8652 - precision: 0.9472 - accuracy: 0.9300 - val_loss: 0.3755 - val_auc: 0.9724 - val_recall: 0.9134 - val_precision: 0.9056 - val_accuracy: 0.9305 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3663 - auc: 0.9731 - recall: 0.8689 - precision: 0.9493 - accuracy: 0.9322 - val_loss: 0.3719 - val_auc: 0.9739 - val_recall: 0.9134 - val_precision: 0.9114 - val_accuracy: 0.9330 - lr: 0.0100\n",
      "Epoch 12/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3641 - auc: 0.9740 - recall: 0.8695 - precision: 0.9500 - accuracy: 0.9326 - val_loss: 0.3702 - val_auc: 0.9744 - val_recall: 0.9134 - val_precision: 0.9134 - val_accuracy: 0.9338 - lr: 0.0100\n",
      "Epoch 13/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3630 - auc: 0.9746 - recall: 0.8714 - precision: 0.9533 - accuracy: 0.9345 - val_loss: 0.3695 - val_auc: 0.9748 - val_recall: 0.9156 - val_precision: 0.9136 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 14/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3624 - auc: 0.9750 - recall: 0.8726 - precision: 0.9540 - accuracy: 0.9352 - val_loss: 0.3691 - val_auc: 0.9750 - val_recall: 0.9177 - val_precision: 0.9138 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 15/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3620 - auc: 0.9753 - recall: 0.8732 - precision: 0.9547 - accuracy: 0.9357 - val_loss: 0.3687 - val_auc: 0.9753 - val_recall: 0.9156 - val_precision: 0.9176 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 16/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3615 - auc: 0.9754 - recall: 0.8751 - precision: 0.9548 - accuracy: 0.9364 - val_loss: 0.3683 - val_auc: 0.9754 - val_recall: 0.9134 - val_precision: 0.9154 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 17/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3611 - auc: 0.9756 - recall: 0.8745 - precision: 0.9548 - accuracy: 0.9362 - val_loss: 0.3679 - val_auc: 0.9756 - val_recall: 0.9156 - val_precision: 0.9156 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 18/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3607 - auc: 0.9757 - recall: 0.8751 - precision: 0.9554 - accuracy: 0.9366 - val_loss: 0.3677 - val_auc: 0.9757 - val_recall: 0.9134 - val_precision: 0.9154 - val_accuracy: 0.9347 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3605 - auc: 0.9759 - recall: 0.8751 - precision: 0.9554 - accuracy: 0.9366 - val_loss: 0.3675 - val_auc: 0.9758 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 20/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3604 - auc: 0.9759 - recall: 0.8751 - precision: 0.9561 - accuracy: 0.9369 - val_loss: 0.3674 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9154 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 21/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3602 - auc: 0.9760 - recall: 0.8751 - precision: 0.9561 - accuracy: 0.9369 - val_loss: 0.3673 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9154 - val_accuracy: 0.9347 - lr: 0.0100\n",
      "Epoch 22/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3601 - auc: 0.9761 - recall: 0.8745 - precision: 0.9554 - accuracy: 0.9364 - val_loss: 0.3672 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 23/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3600 - auc: 0.9761 - recall: 0.8738 - precision: 0.9554 - accuracy: 0.9362 - val_loss: 0.3671 - val_auc: 0.9760 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 24/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3598 - auc: 0.9761 - recall: 0.8738 - precision: 0.9554 - accuracy: 0.9362 - val_loss: 0.3670 - val_auc: 0.9760 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 25/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3597 - auc: 0.9761 - recall: 0.8738 - precision: 0.9554 - accuracy: 0.9362 - val_loss: 0.3669 - val_auc: 0.9760 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 26/250\n",
      "133/133 [==============================] - 1s 6ms/step - loss: 0.3595 - auc: 0.9761 - recall: 0.8732 - precision: 0.9553 - accuracy: 0.9359 - val_loss: 0.3667 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 27/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3594 - auc: 0.9761 - recall: 0.8732 - precision: 0.9560 - accuracy: 0.9362 - val_loss: 0.3666 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 28/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3592 - auc: 0.9761 - recall: 0.8738 - precision: 0.9567 - accuracy: 0.9366 - val_loss: 0.3664 - val_auc: 0.9759 - val_recall: 0.9134 - val_precision: 0.9194 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 29/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3591 - auc: 0.9762 - recall: 0.8732 - precision: 0.9566 - accuracy: 0.9364 - val_loss: 0.3663 - val_auc: 0.9760 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 30/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3589 - auc: 0.9761 - recall: 0.8732 - precision: 0.9566 - accuracy: 0.9364 - val_loss: 0.3661 - val_auc: 0.9759 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 31/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3588 - auc: 0.9762 - recall: 0.8726 - precision: 0.9566 - accuracy: 0.9362 - val_loss: 0.3659 - val_auc: 0.9759 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 32/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3587 - auc: 0.9761 - recall: 0.8720 - precision: 0.9566 - accuracy: 0.9359 - val_loss: 0.3658 - val_auc: 0.9758 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 33/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3585 - auc: 0.9761 - recall: 0.8732 - precision: 0.9566 - accuracy: 0.9364 - val_loss: 0.3656 - val_auc: 0.9758 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 34/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3584 - auc: 0.9761 - recall: 0.8726 - precision: 0.9566 - accuracy: 0.9362 - val_loss: 0.3654 - val_auc: 0.9758 - val_recall: 0.9156 - val_precision: 0.9196 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 35/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3583 - auc: 0.9761 - recall: 0.8720 - precision: 0.9572 - accuracy: 0.9362 - val_loss: 0.3653 - val_auc: 0.9758 - val_recall: 0.9177 - val_precision: 0.9197 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 36/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3582 - auc: 0.9761 - recall: 0.8726 - precision: 0.9573 - accuracy: 0.9364 - val_loss: 0.3651 - val_auc: 0.9758 - val_recall: 0.9177 - val_precision: 0.9217 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 37/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3581 - auc: 0.9760 - recall: 0.8738 - precision: 0.9573 - accuracy: 0.9369 - val_loss: 0.3649 - val_auc: 0.9758 - val_recall: 0.9177 - val_precision: 0.9237 - val_accuracy: 0.9396 - lr: 0.0100\n",
      "Epoch 38/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3580 - auc: 0.9760 - recall: 0.8732 - precision: 0.9573 - accuracy: 0.9366 - val_loss: 0.3648 - val_auc: 0.9759 - val_recall: 0.9177 - val_precision: 0.9258 - val_accuracy: 0.9404 - lr: 0.0100\n",
      "Epoch 39/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3579 - auc: 0.9761 - recall: 0.8732 - precision: 0.9573 - accuracy: 0.9366 - val_loss: 0.3646 - val_auc: 0.9759 - val_recall: 0.9177 - val_precision: 0.9217 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 40/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3578 - auc: 0.9761 - recall: 0.8732 - precision: 0.9573 - accuracy: 0.9366 - val_loss: 0.3645 - val_auc: 0.9760 - val_recall: 0.9177 - val_precision: 0.9217 - val_accuracy: 0.9388 - lr: 0.0100\n",
      "Epoch 41/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3578 - auc: 0.9761 - recall: 0.8745 - precision: 0.9573 - accuracy: 0.9371 - val_loss: 0.3644 - val_auc: 0.9760 - val_recall: 0.9156 - val_precision: 0.9216 - val_accuracy: 0.9380 - lr: 0.0100\n",
      "Epoch 42/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3577 - auc: 0.9761 - recall: 0.8738 - precision: 0.9573 - accuracy: 0.9369 - val_loss: 0.3644 - val_auc: 0.9761 - val_recall: 0.9134 - val_precision: 0.9214 - val_accuracy: 0.9371 - lr: 0.0100\n",
      "Epoch 43/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3577 - auc: 0.9761 - recall: 0.8732 - precision: 0.9573 - accuracy: 0.9366 - val_loss: 0.3645 - val_auc: 0.9760 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 44/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3576 - auc: 0.9761 - recall: 0.8738 - precision: 0.9573 - accuracy: 0.9369 - val_loss: 0.3643 - val_auc: 0.9760 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 45/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3575 - auc: 0.9761 - recall: 0.8726 - precision: 0.9573 - accuracy: 0.9364 - val_loss: 0.3641 - val_auc: 0.9760 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 46/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3575 - auc: 0.9761 - recall: 0.8726 - precision: 0.9579 - accuracy: 0.9366 - val_loss: 0.3640 - val_auc: 0.9761 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 47/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3574 - auc: 0.9761 - recall: 0.8738 - precision: 0.9580 - accuracy: 0.9371 - val_loss: 0.3638 - val_auc: 0.9761 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 48/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3573 - auc: 0.9761 - recall: 0.8738 - precision: 0.9580 - accuracy: 0.9371 - val_loss: 0.3637 - val_auc: 0.9761 - val_recall: 0.9113 - val_precision: 0.9212 - val_accuracy: 0.9363 - lr: 0.0100\n",
      "Epoch 49/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3573 - auc: 0.9761 - recall: 0.8732 - precision: 0.9579 - accuracy: 0.9369 - val_loss: 0.3636 - val_auc: 0.9761 - val_recall: 0.9113 - val_precision: 0.9192 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 50/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3572 - auc: 0.9761 - recall: 0.8732 - precision: 0.9579 - accuracy: 0.9369 - val_loss: 0.3634 - val_auc: 0.9761 - val_recall: 0.9113 - val_precision: 0.9192 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 51/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3572 - auc: 0.9762 - recall: 0.8732 - precision: 0.9579 - accuracy: 0.9369 - val_loss: 0.3633 - val_auc: 0.9762 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 52/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3571 - auc: 0.9762 - recall: 0.8745 - precision: 0.9580 - accuracy: 0.9374 - val_loss: 0.3632 - val_auc: 0.9762 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 53/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3571 - auc: 0.9762 - recall: 0.8745 - precision: 0.9580 - accuracy: 0.9374 - val_loss: 0.3631 - val_auc: 0.9762 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 54/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3570 - auc: 0.9763 - recall: 0.8745 - precision: 0.9580 - accuracy: 0.9374 - val_loss: 0.3630 - val_auc: 0.9763 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 55/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3569 - auc: 0.9763 - recall: 0.8745 - precision: 0.9580 - accuracy: 0.9374 - val_loss: 0.3629 - val_auc: 0.9763 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 56/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3569 - auc: 0.9764 - recall: 0.8751 - precision: 0.9580 - accuracy: 0.9376 - val_loss: 0.3629 - val_auc: 0.9763 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 57/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3568 - auc: 0.9764 - recall: 0.8751 - precision: 0.9580 - accuracy: 0.9376 - val_loss: 0.3628 - val_auc: 0.9763 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 58/250\n",
      "133/133 [==============================] - 1s 5ms/step - loss: 0.3567 - auc: 0.9765 - recall: 0.8745 - precision: 0.9580 - accuracy: 0.9374 - val_loss: 0.3628 - val_auc: 0.9764 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "Epoch 59/250\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.3566 - auc: 0.9765 - recall: 0.8745 - precision: 0.9573 - accuracy: 0.9371 - val_loss: 0.3627 - val_auc: 0.9764 - val_recall: 0.9134 - val_precision: 0.9174 - val_accuracy: 0.9355 - lr: 0.0100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3471 - auc: 0.9841 - recall: 0.9264 - precision: 0.9345 - accuracy: 0.9471\n"
     ]
    }
   ],
   "source": [
    "results, models, histories = process_models(l2_regularizers, init_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "81c20203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3c943a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8156028389930725,\n",
       " 0.8810874819755554,\n",
       " 0.895035445690155,\n",
       " 0.9026004672050476,\n",
       " 0.9066193699836731,\n",
       " 0.9120567440986633,\n",
       " 0.9144207835197449,\n",
       " 0.9177305102348328,\n",
       " 0.9196217656135559,\n",
       " 0.9208037853240967,\n",
       " 0.922931432723999,\n",
       " 0.9236406683921814,\n",
       " 0.9243499040603638,\n",
       " 0.9257683157920837,\n",
       " 0.9271867871284485,\n",
       " 0.9283688068389893,\n",
       " 0.9286051988601685,\n",
       " 0.9297872185707092,\n",
       " 0.9302600622177124,\n",
       " 0.9307328462600708,\n",
       " 0.931205689907074,\n",
       " 0.9314420819282532,\n",
       " 0.9316784739494324,\n",
       " 0.9319148659706116,\n",
       " 0.9319148659706116,\n",
       " 0.9319148659706116,\n",
       " 0.9321513175964355,\n",
       " 0.9316784739494324,\n",
       " 0.9321513175964355,\n",
       " 0.9323877096176147,\n",
       " 0.9319148659706116,\n",
       " 0.9319148659706116,\n",
       " 0.9316784739494324,\n",
       " 0.9316784739494324,\n",
       " 0.9319148659706116,\n",
       " 0.9319148659706116,\n",
       " 0.9323877096176147,\n",
       " 0.932624101638794,\n",
       " 0.9323877096176147,\n",
       " 0.9321513175964355,\n",
       " 0.9316784739494324,\n",
       " 0.9316784739494324,\n",
       " 0.9314420819282532,\n",
       " 0.9314420819282532,\n",
       " 0.931205689907074,\n",
       " 0.9314420819282532,\n",
       " 0.9314420819282532,\n",
       " 0.9314420819282532,\n",
       " 0.9319148659706116,\n",
       " 0.9323877096176147,\n",
       " 0.9321513175964355,\n",
       " 0.9321513175964355,\n",
       " 0.9321513175964355,\n",
       " 0.9321513175964355,\n",
       " 0.9321513175964355,\n",
       " 0.932624101638794,\n",
       " 0.9328604936599731,\n",
       " 0.9323877096176147,\n",
       " 0.932624101638794,\n",
       " 0.9323877096176147,\n",
       " 0.9321513175964355,\n",
       " 0.9323877096176147,\n",
       " 0.932624101638794,\n",
       " 0.932624101638794,\n",
       " 0.932624101638794,\n",
       " 0.9328604936599731,\n",
       " 0.9333333373069763,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9338061213493347,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9338061213493347,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9340425729751587,\n",
       " 0.9342789649963379,\n",
       " 0.9345153570175171,\n",
       " 0.9345153570175171,\n",
       " 0.9347517490386963,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9349882006645203,\n",
       " 0.9349882006645203,\n",
       " 0.9349882006645203,\n",
       " 0.9352245926856995,\n",
       " 0.9354609847068787,\n",
       " 0.9352245926856995,\n",
       " 0.9349882006645203,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9352245926856995,\n",
       " 0.9356973767280579,\n",
       " 0.9356973767280579,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9356973767280579,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.936170220375061,\n",
       " 0.9356973767280579,\n",
       " 0.9356973767280579,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9354609847068787,\n",
       " 0.9368794560432434,\n",
       " 0.9364066123962402,\n",
       " 0.9364066123962402,\n",
       " 0.936170220375061,\n",
       " 0.9364066123962402,\n",
       " 0.9366430044174194,\n",
       " 0.936170220375061,\n",
       " 0.936170220375061,\n",
       " 0.936170220375061,\n",
       " 0.936170220375061]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories[0].history['binary_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d85e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "96b6d2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5004), started 2 days, 20:54:08 ago. (Use '!kill 5004' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b05c79635144632\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b05c79635144632\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb52c7a",
   "metadata": {},
   "source": [
    "# ======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8084023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008 <keras.initializers.initializers_v2.GlorotNormal object at 0x0000023A96173CA0>\n",
      "(-0.7339059, 0.83242553, -1.3700318, 1.2127553)\n",
      "[0.37099191546440125, 0.9836100339889526, 0.9004328846931458, 0.9629629850387573, 0.9487603306770325]\n",
      "-----------\n",
      "0.007 <keras.initializers.initializers_v2.GlorotNormal object at 0x0000023A973B4130>\n",
      "(-0.731272, 0.8421514, -1.5766361, 1.1370975)\n",
      "[0.3565647602081299, 0.9828633666038513, 0.9134199023246765, 0.9504504799842834, 0.9487603306770325]\n",
      "-----------\n",
      "0.006 <keras.initializers.initializers_v2.GlorotNormal object at 0x0000023A95ECD730>\n",
      "(-0.89648986, 0.7053443, -1.0143557, 1.4345479)\n",
      "[0.3416169583797455, 0.9828518629074097, 0.9177489280700684, 0.9464285969734192, 0.9487603306770325]\n",
      "-----------\n",
      "0.008 <keras.initializers.initializers_v2.HeNormal object at 0x0000023A9B929A30>\n",
      "(-0.7795853, 0.82940185, -1.4127246, 1.3651894)\n",
      "[0.3692987263202667, 0.9840613603591919, 0.9090909361839294, 0.963302731513977, 0.9520661234855652]\n",
      "-----------\n",
      "0.007 <keras.initializers.initializers_v2.HeNormal object at 0x0000023A9CB86F40>\n",
      "(-0.70945555, 0.86639446, -1.4017054, 0.8972346)\n",
      "[0.35850539803504944, 0.9819894433021545, 0.9004328846931458, 0.9541284441947937, 0.9454545378684998]\n",
      "-----------\n",
      "0.006 <keras.initializers.initializers_v2.HeNormal object at 0x0000023A9EDB0400>\n",
      "(-0.78898066, 0.63953465, -1.0536029, 1.5293388)\n",
      "[0.3317926526069641, 0.9848021268844604, 0.9220778942108154, 0.9551569223403931, 0.9537190198898315]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for idx, model in enumerate(models):\n",
    "    weights = np.min(model.get_weights()[0]), np.max(model.get_weights()[0]), np.min(model.get_weights()[1]), np.max(model.get_weights()[1])\n",
    "    print(model.layers[1].kernel_regularizer.l2, model.layers[1].kernel_initializer)\n",
    "    print(weights)\n",
    "    print(results[idx])\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "844d975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008 <keras.initializers.initializers_v2.GlorotNormal object at 0x000001A5D7BE7610>\n",
      "(-0.850345, 0.8334865, -1.2260424, 1.6032988)\n",
      "[0.368624746799469, 0.9454545378684998]\n",
      "-----------\n",
      "0.007 <keras.initializers.initializers_v2.GlorotNormal object at 0x000001A5D7BDA310>\n",
      "(-0.7647453, 0.92581064, -1.3860332, 1.1354349)\n",
      "[0.35585373640060425, 0.9438016414642334]\n",
      "-----------\n",
      "0.006 <keras.initializers.initializers_v2.GlorotNormal object at 0x000001A5DAE54400>\n",
      "(-0.6860807, 0.85149384, -1.2082765, 1.5861523)\n",
      "[0.3309980630874634, 0.9553719162940979]\n",
      "-----------\n",
      "0.008 <keras.initializers.initializers_v2.HeNormal object at 0x000001A5DAE8B4F0>\n",
      "(-0.6180524, 0.74834824, -1.3511591, 1.3180828)\n",
      "[0.3736017048358917, 0.9520661234855652]\n",
      "-----------\n",
      "0.007 <keras.initializers.initializers_v2.HeNormal object at 0x000001A5DC0BCD00>\n",
      "(-0.8114171, 0.7657546, -1.3345479, 1.0654538)\n",
      "[0.34865325689315796, 0.9570248126983643]\n",
      "-----------\n",
      "0.006 <keras.initializers.initializers_v2.HeNormal object at 0x000001A5DC241400>\n",
      "(-0.8427416, 0.76636666, -1.241308, 1.3565598)\n",
      "[0.33406588435173035, 0.9520661234855652]\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# STARE\n",
    "# for idx, model in enumerate(models):\n",
    "#     weights = np.min(model.get_weights()[0]), np.max(model.get_weights()[0]), np.min(model.get_weights()[1]), np.max(model.get_weights()[1])\n",
    "#     print(model.layers[1].kernel_regularizer.l2, model.layers[1].kernel_initializer)\n",
    "#     print(weights)\n",
    "#     print(results[idx])\n",
    "#     print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4b92a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[4].save_weights('./checkpoints/my_checkpoint2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1747e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model2\\assets\n"
     ]
    }
   ],
   "source": [
    "models[4].save('./saved_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1e10f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_113 (Flatten)       (None, 10)                0         \n",
      "                                                                 \n",
      " dense_226 (Dense)           (None, 10)                100       \n",
      "                                                                 \n",
      " custom_sigmoid (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      " dense_227 (Dense)           (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110\n",
      "Trainable params: 110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0e6f7bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(models[1], to_file=\"my_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f723cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "d4d8ec30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.13'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ee0b71fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14916\\1687819689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'result'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
